{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Rusty Bargain, a used car company, is developing an app to help customers predict the market value of their own car. By using historical data on technical specifications and prices, they hope to implement a model that is accurate and time efficient.\n",
    "\n",
    "## Data Description\n",
    "\n",
    "Rusty Bargain has provided the following data:\n",
    "\n",
    "**Features**\n",
    "\n",
    "- `DateCrawled` — date profile was downloaded from the database\n",
    "- `VehicleType` - vehicle body type\n",
    "- `RegistrationYear` - vehicle registration year\n",
    "- `Gearbox` - gearbox type\n",
    "- `Power` - power (hp)\n",
    "- `Model` - vehicle model\n",
    "- `Mileage` — mileage (measured in km due to dataset's regional specifics)\n",
    "- `RegistrationMonth` - vehicle registration month\n",
    "- `FuelType` - fuel type\n",
    "- `Brand` - vehicle brand\n",
    "- `NotRepaired` - vehicle repaired or not\n",
    "- `DateCreated` - date of profile creation\n",
    "- `NumberOfPictures` - number of vehicle pictures\n",
    "- `PostalCode` - postal code of profile owner (user)\n",
    "- `LastSeen` - date of the last activity of the user\n",
    "\n",
    "**Target**\n",
    "\n",
    "- `Price` — price (Euro)\n",
    "\n",
    "## Process\n",
    "\n",
    "The process will include the following three steps:\n",
    "1. Data Preparation\n",
    "2. Model Training\n",
    "3. Model Analysis\n",
    "\n",
    "### Preparation\n",
    "\n",
    "The data will first be prepared. This will include:\n",
    "- Importing packages\n",
    "- Reading the dataframe\n",
    "- Inspecting the dataframe\n",
    "- Converting datatypes\n",
    "- Dropping unnecessary columns\n",
    "- Handling missing data\n",
    "- Encoding data\n",
    "\n",
    "### Training\n",
    "\n",
    "Training will be done on four different models:\n",
    "\n",
    "- Linear regression (1 model)\n",
    "- Random forest (1 model)\n",
    "- Gradient descent (2 models)\n",
    "\n",
    "Each will require splitting data and training according to their specific hyperparameters.\n",
    "\n",
    "### Analysis\n",
    "\n",
    "Model efficiency will be compared. This can be broken down to how accurate and how quick the model is. Accuracy will be measured with reference to the root of the mean square error (RMSE). The lower the number, the better. Each model will also be evaluated by how long each model takes along with how long the best model takes whilst iterating through hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation\n",
    "\n",
    "Import relevant packages and save dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import re # to re-format column names\n",
    "from datetime import date # to calculate age\n",
    "from sklearn.model_selection import train_test_split # to split data\n",
    "from sklearn.preprocessing import OneHotEncoder # for encoding\n",
    "from sklearn.preprocessing import OrdinalEncoder # for encoding\n",
    "import time # to calculate execution time\n",
    "from sklearn.linear_model import LinearRegression # for linear regression modelling\n",
    "from sklearn.metrics import mean_squared_error # to calculate MSE\n",
    "from sklearn.ensemble import RandomForestRegressor # for random forest modelling\n",
    "import lightgbm as lgb # for lightGBM modelling\n",
    "from catboost import CatBoostRegressor # for catboost modelling\n",
    "import time # to calculate execution time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv('data/car_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect Columns\n",
    "\n",
    "Inspect column information to ensure column names are approriate and that columns contain the correct datatype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateCrawled</th>\n",
       "      <th>Price</th>\n",
       "      <th>VehicleType</th>\n",
       "      <th>RegistrationYear</th>\n",
       "      <th>Gearbox</th>\n",
       "      <th>Power</th>\n",
       "      <th>Model</th>\n",
       "      <th>Mileage</th>\n",
       "      <th>RegistrationMonth</th>\n",
       "      <th>FuelType</th>\n",
       "      <th>Brand</th>\n",
       "      <th>NotRepaired</th>\n",
       "      <th>DateCreated</th>\n",
       "      <th>NumberOfPictures</th>\n",
       "      <th>PostalCode</th>\n",
       "      <th>LastSeen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24/03/2016 11:52</td>\n",
       "      <td>480</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1993</td>\n",
       "      <td>manual</td>\n",
       "      <td>0</td>\n",
       "      <td>golf</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>petrol</td>\n",
       "      <td>volkswagen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24/03/2016 00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>70435</td>\n",
       "      <td>07/04/2016 03:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24/03/2016 10:58</td>\n",
       "      <td>18300</td>\n",
       "      <td>coupe</td>\n",
       "      <td>2011</td>\n",
       "      <td>manual</td>\n",
       "      <td>190</td>\n",
       "      <td>NaN</td>\n",
       "      <td>125000</td>\n",
       "      <td>5</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>audi</td>\n",
       "      <td>yes</td>\n",
       "      <td>24/03/2016 00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>66954</td>\n",
       "      <td>07/04/2016 01:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14/03/2016 12:52</td>\n",
       "      <td>9800</td>\n",
       "      <td>suv</td>\n",
       "      <td>2004</td>\n",
       "      <td>auto</td>\n",
       "      <td>163</td>\n",
       "      <td>grand</td>\n",
       "      <td>125000</td>\n",
       "      <td>8</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>jeep</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14/03/2016 00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>90480</td>\n",
       "      <td>05/04/2016 12:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17/03/2016 16:54</td>\n",
       "      <td>1500</td>\n",
       "      <td>small</td>\n",
       "      <td>2001</td>\n",
       "      <td>manual</td>\n",
       "      <td>75</td>\n",
       "      <td>golf</td>\n",
       "      <td>150000</td>\n",
       "      <td>6</td>\n",
       "      <td>petrol</td>\n",
       "      <td>volkswagen</td>\n",
       "      <td>no</td>\n",
       "      <td>17/03/2016 00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>91074</td>\n",
       "      <td>17/03/2016 17:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31/03/2016 17:25</td>\n",
       "      <td>3600</td>\n",
       "      <td>small</td>\n",
       "      <td>2008</td>\n",
       "      <td>manual</td>\n",
       "      <td>69</td>\n",
       "      <td>fabia</td>\n",
       "      <td>90000</td>\n",
       "      <td>7</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>skoda</td>\n",
       "      <td>no</td>\n",
       "      <td>31/03/2016 00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>60437</td>\n",
       "      <td>06/04/2016 10:17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        DateCrawled  Price VehicleType  RegistrationYear Gearbox  Power  \\\n",
       "0  24/03/2016 11:52    480         NaN              1993  manual      0   \n",
       "1  24/03/2016 10:58  18300       coupe              2011  manual    190   \n",
       "2  14/03/2016 12:52   9800         suv              2004    auto    163   \n",
       "3  17/03/2016 16:54   1500       small              2001  manual     75   \n",
       "4  31/03/2016 17:25   3600       small              2008  manual     69   \n",
       "\n",
       "   Model  Mileage  RegistrationMonth  FuelType       Brand NotRepaired  \\\n",
       "0   golf   150000                  0    petrol  volkswagen         NaN   \n",
       "1    NaN   125000                  5  gasoline        audi         yes   \n",
       "2  grand   125000                  8  gasoline        jeep         NaN   \n",
       "3   golf   150000                  6    petrol  volkswagen          no   \n",
       "4  fabia    90000                  7  gasoline       skoda          no   \n",
       "\n",
       "        DateCreated  NumberOfPictures  PostalCode          LastSeen  \n",
       "0  24/03/2016 00:00                 0       70435  07/04/2016 03:16  \n",
       "1  24/03/2016 00:00                 0       66954  07/04/2016 01:46  \n",
       "2  14/03/2016 00:00                 0       90480  05/04/2016 12:47  \n",
       "3  17/03/2016 00:00                 0       91074  17/03/2016 17:40  \n",
       "4  31/03/2016 00:00                 0       60437  06/04/2016 10:17  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check head of dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column Names\n",
    "\n",
    "Columns are currently in `CamelCase` which are hard to read. These will be changed to `snake_case`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change columns from CamelCase to snake_case\n",
    "df.columns = [re.sub(r'(?<!^)(?=[A-Z])', '_', col).lower() for col in df.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 354369 entries, 0 to 354368\n",
      "Data columns (total 16 columns):\n",
      " #   Column              Non-Null Count   Dtype \n",
      "---  ------              --------------   ----- \n",
      " 0   date_crawled        354369 non-null  object\n",
      " 1   price               354369 non-null  int64 \n",
      " 2   vehicle_type        316879 non-null  object\n",
      " 3   registration_year   354369 non-null  int64 \n",
      " 4   gearbox             334536 non-null  object\n",
      " 5   power               354369 non-null  int64 \n",
      " 6   model               334664 non-null  object\n",
      " 7   mileage             354369 non-null  int64 \n",
      " 8   registration_month  354369 non-null  int64 \n",
      " 9   fuel_type           321474 non-null  object\n",
      " 10  brand               354369 non-null  object\n",
      " 11  not_repaired        283215 non-null  object\n",
      " 12  date_created        354369 non-null  object\n",
      " 13  number_of_pictures  354369 non-null  int64 \n",
      " 14  postal_code         354369 non-null  int64 \n",
      " 15  last_seen           354369 non-null  object\n",
      "dtypes: int64(7), object(9)\n",
      "memory usage: 43.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# check info to inspect data types\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Date Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save date columns to list\n",
    "date_cols = ['date_crawled', 'date_created', 'last_seen']\n",
    "\n",
    "# parse dates in correct format\n",
    "for col in date_cols:\n",
    "    df[col] = pd.to_datetime(df[col], format = '%d/%m/%Y %H:%M')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "262"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find number of duplicate values \n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop duplicates\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect Values\n",
    "\n",
    "For dates, integer and float columns, inspect outliers with respect to summary statistics. Compare minimum and maximum values with what is logically possible. For instace, all prices should be positive. \n",
    "\n",
    "### Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_crawled</th>\n",
       "      <th>price</th>\n",
       "      <th>registration_year</th>\n",
       "      <th>power</th>\n",
       "      <th>mileage</th>\n",
       "      <th>registration_month</th>\n",
       "      <th>date_created</th>\n",
       "      <th>number_of_pictures</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>last_seen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>354107</td>\n",
       "      <td>354107.000000</td>\n",
       "      <td>354107.000000</td>\n",
       "      <td>354107.000000</td>\n",
       "      <td>354107.000000</td>\n",
       "      <td>354107.000000</td>\n",
       "      <td>354107</td>\n",
       "      <td>354107.0</td>\n",
       "      <td>354107.000000</td>\n",
       "      <td>354107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2016-03-21 12:56:48.735947008</td>\n",
       "      <td>4416.433287</td>\n",
       "      <td>2004.235355</td>\n",
       "      <td>110.089651</td>\n",
       "      <td>128211.811684</td>\n",
       "      <td>5.714182</td>\n",
       "      <td>2016-03-20 19:11:13.738728960</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50507.145030</td>\n",
       "      <td>2016-03-29 23:51:12.374903808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2016-03-05 14:06:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2014-03-10 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1067.000000</td>\n",
       "      <td>2016-03-05 14:15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2016-03-13 11:52:00</td>\n",
       "      <td>1050.000000</td>\n",
       "      <td>1999.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>125000.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2016-03-13 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30165.000000</td>\n",
       "      <td>2016-03-23 02:50:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2016-03-21 17:50:00</td>\n",
       "      <td>2700.000000</td>\n",
       "      <td>2003.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2016-03-21 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49406.000000</td>\n",
       "      <td>2016-04-03 15:15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2016-03-29 14:36:00</td>\n",
       "      <td>6400.000000</td>\n",
       "      <td>2008.000000</td>\n",
       "      <td>143.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2016-03-29 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71083.000000</td>\n",
       "      <td>2016-04-06 10:06:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2016-04-07 14:36:00</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>9999.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2016-04-07 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99998.000000</td>\n",
       "      <td>2016-04-07 14:58:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4514.338584</td>\n",
       "      <td>90.261168</td>\n",
       "      <td>189.914972</td>\n",
       "      <td>37906.590101</td>\n",
       "      <td>3.726682</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25784.212094</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        date_crawled          price  registration_year  \\\n",
       "count                         354107  354107.000000      354107.000000   \n",
       "mean   2016-03-21 12:56:48.735947008    4416.433287        2004.235355   \n",
       "min              2016-03-05 14:06:00       0.000000        1000.000000   \n",
       "25%              2016-03-13 11:52:00    1050.000000        1999.000000   \n",
       "50%              2016-03-21 17:50:00    2700.000000        2003.000000   \n",
       "75%              2016-03-29 14:36:00    6400.000000        2008.000000   \n",
       "max              2016-04-07 14:36:00   20000.000000        9999.000000   \n",
       "std                              NaN    4514.338584          90.261168   \n",
       "\n",
       "               power        mileage  registration_month  \\\n",
       "count  354107.000000  354107.000000       354107.000000   \n",
       "mean      110.089651  128211.811684            5.714182   \n",
       "min         0.000000    5000.000000            0.000000   \n",
       "25%        69.000000  125000.000000            3.000000   \n",
       "50%       105.000000  150000.000000            6.000000   \n",
       "75%       143.000000  150000.000000            9.000000   \n",
       "max     20000.000000  150000.000000           12.000000   \n",
       "std       189.914972   37906.590101            3.726682   \n",
       "\n",
       "                        date_created  number_of_pictures    postal_code  \\\n",
       "count                         354107            354107.0  354107.000000   \n",
       "mean   2016-03-20 19:11:13.738728960                 0.0   50507.145030   \n",
       "min              2014-03-10 00:00:00                 0.0    1067.000000   \n",
       "25%              2016-03-13 00:00:00                 0.0   30165.000000   \n",
       "50%              2016-03-21 00:00:00                 0.0   49406.000000   \n",
       "75%              2016-03-29 00:00:00                 0.0   71083.000000   \n",
       "max              2016-04-07 00:00:00                 0.0   99998.000000   \n",
       "std                              NaN                 0.0   25784.212094   \n",
       "\n",
       "                           last_seen  \n",
       "count                         354107  \n",
       "mean   2016-03-29 23:51:12.374903808  \n",
       "min              2016-03-05 14:15:00  \n",
       "25%              2016-03-23 02:50:00  \n",
       "50%              2016-04-03 15:15:00  \n",
       "75%              2016-04-06 10:06:00  \n",
       "max              2016-04-07 14:58:00  \n",
       "std                              NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect summary statistics for non-categorical data\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Registration Year\n",
    "Registration year contains dates for cars that are registered before cars were invented or in the future from the time of the data collection. These years will be replaced with null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace car registration years that are not between 1900 and 2016 with NaN\n",
    "df['registration_year'] = df['registration_year'].apply(lambda x: x if 1900 < x < 2016 else np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Power\n",
    "A quick google search will reveal that the highest horse power of any car in 2016 eclipses at 1500. Cars with a horse power listed at 0 are also unlikely to be so. Values above this will be replaced with null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace horse power values that are not between 1 and 2000 with 0\n",
    "df['power'] = df['power'].apply(lambda x: x if 1 < x < 1500 else np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pictures\n",
    "Every row in the dataset contains zero pictures. This column will be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop picture column\n",
    "df = df.drop('number_of_pictures', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Registration Month\n",
    "\n",
    "Thirteen values have been provided (0-12) when only 12 months exist. This column will be dropped as it is not possible to distinguish where the months start and end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop registration month column\n",
    "df = df.drop('registration_month', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Date Crawled\n",
    "\n",
    "Now that dates have been confirmed, this column can be dropped as it has no impact on the modelling process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop date_crawled column\n",
    "df = df.drop('date_crawled', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Last Seen\n",
    "\n",
    "Whilst the date in which a car was last seen may indicate how much traffic the page has received, it is not useful for our analysis. We will drop this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop last_seen column\n",
    "df = df.drop('last_seen', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Date Created\n",
    "\n",
    "Date time cannot be analysed as a continuous variable. Instead, we will extract the number of days since the ad was created and scale it accordingly. The date_created column will then be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find days since car was created\n",
    "df['age'] = (df['date_created'].max() - df['date_created'])\n",
    "\n",
    "# convert age to days\n",
    "df['age'] = df['age'].apply(lambda x: x.days)\n",
    "\n",
    "# drop date_created column\n",
    "df = df.drop('date_created', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical columns\n",
    "\n",
    "Categorical columns will be inspected for typos and inconsistencies by finding their unique values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vehicle_type \n",
      " ['bus' 'convertible' 'coupe' 'nan' 'other' 'sedan' 'small' 'suv' 'wagon'] \n",
      "\n",
      "gearbox \n",
      " ['auto' 'manual' 'nan'] \n",
      "\n",
      "model \n",
      " ['100' '145' '147' '156' '159' '1_reihe' '1er' '200' '2_reihe' '300c'\n",
      " '3_reihe' '3er' '4_reihe' '500' '5_reihe' '5er' '601' '6_reihe' '6er'\n",
      " '7er' '80' '850' '90' '900' '9000' '911' 'a1' 'a2' 'a3' 'a4' 'a5' 'a6'\n",
      " 'a8' 'a_klasse' 'accord' 'agila' 'alhambra' 'almera' 'altea' 'amarok'\n",
      " 'antara' 'arosa' 'astra' 'auris' 'avensis' 'aveo' 'aygo' 'b_klasse'\n",
      " 'b_max' 'beetle' 'berlingo' 'bora' 'boxster' 'bravo' 'c1' 'c2' 'c3' 'c4'\n",
      " 'c5' 'c_klasse' 'c_max' 'c_reihe' 'caddy' 'calibra' 'captiva' 'carisma'\n",
      " 'carnival' 'cayenne' 'cc' 'ceed' 'charade' 'cherokee' 'citigo' 'civic'\n",
      " 'cl' 'clio' 'clk' 'clubman' 'colt' 'combo' 'cooper' 'cordoba' 'corolla'\n",
      " 'corsa' 'cr_reihe' 'croma' 'crossfire' 'cuore' 'cx_reihe' 'defender'\n",
      " 'delta' 'discovery' 'doblo' 'ducato' 'duster' 'e_klasse' 'elefantino'\n",
      " 'eos' 'escort' 'espace' 'exeo' 'fabia' 'fiesta' 'focus' 'forester'\n",
      " 'forfour' 'fortwo' 'fox' 'freelander' 'fusion' 'g_klasse' 'galant'\n",
      " 'galaxy' 'getz' 'gl' 'glk' 'golf' 'grand' 'i3' 'i_reihe' 'ibiza'\n",
      " 'impreza' 'insignia' 'jazz' 'jetta' 'jimny' 'juke' 'justy' 'ka' 'kadett'\n",
      " 'kaefer' 'kalina' 'kalos' 'kangoo' 'kappa' 'kuga' 'laguna' 'lancer'\n",
      " 'lanos' 'legacy' 'leon' 'lodgy' 'logan' 'lupo' 'lybra' 'm_klasse'\n",
      " 'm_reihe' 'materia' 'matiz' 'megane' 'meriva' 'micra' 'mii' 'modus'\n",
      " 'mondeo' 'move' 'musa' 'mustang' 'mx_reihe' 'nan' 'navara' 'niva' 'note'\n",
      " 'nubira' 'octavia' 'omega' 'one' 'other' 'outlander' 'pajero' 'panda'\n",
      " 'passat' 'phaeton' 'picanto' 'polo' 'primera' 'ptcruiser' 'punto' 'q3'\n",
      " 'q5' 'q7' 'qashqai' 'r19' 'range_rover' 'range_rover_evoque'\n",
      " 'range_rover_sport' 'rangerover' 'rav' 'rio' 'roadster' 'roomster'\n",
      " 'rx_reihe' 's60' 's_klasse' 's_max' 's_type' 'samara' 'sandero' 'santa'\n",
      " 'scenic' 'scirocco' 'seicento' 'serie_1' 'serie_2' 'serie_3' 'sharan'\n",
      " 'signum' 'sirion' 'sl' 'slk' 'sorento' 'spark' 'spider' 'sportage'\n",
      " 'sprinter' 'stilo' 'superb' 'swift' 'terios' 'tigra' 'tiguan' 'toledo'\n",
      " 'touareg' 'touran' 'transit' 'transporter' 'tt' 'tucson' 'twingo' 'up'\n",
      " 'v40' 'v50' 'v60' 'v70' 'v_klasse' 'vectra' 'verso' 'viano' 'vito'\n",
      " 'vivaro' 'voyager' 'wrangler' 'x_reihe' 'x_trail' 'x_type' 'xc_reihe'\n",
      " 'yaris' 'yeti' 'ypsilon' 'z_reihe' 'zafira'] \n",
      "\n",
      "fuel_type \n",
      " ['cng' 'electric' 'gasoline' 'hybrid' 'lpg' 'nan' 'other' 'petrol'] \n",
      "\n",
      "brand \n",
      " ['alfa_romeo' 'audi' 'bmw' 'chevrolet' 'chrysler' 'citroen' 'dacia'\n",
      " 'daewoo' 'daihatsu' 'fiat' 'ford' 'honda' 'hyundai' 'jaguar' 'jeep' 'kia'\n",
      " 'lada' 'lancia' 'land_rover' 'mazda' 'mercedes_benz' 'mini' 'mitsubishi'\n",
      " 'nissan' 'opel' 'peugeot' 'porsche' 'renault' 'rover' 'saab' 'seat'\n",
      " 'skoda' 'smart' 'sonstige_autos' 'subaru' 'suzuki' 'toyota' 'trabant'\n",
      " 'volkswagen' 'volvo'] \n",
      "\n",
      "not_repaired \n",
      " ['nan' 'no' 'yes'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# find categorical columns\n",
    "categorical = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "# print unique values of categorical columns\n",
    "for col in categorical:\n",
    "    unique_values = np.sort(df[col].unique().astype(str))\n",
    "    print(col, '\\n', unique_values,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From inspection, no typos or errors were found in categorical columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Data\n",
    "\n",
    "Check missing data as a percentage of given data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "not_repaired         20.09\n",
       "power                11.43\n",
       "vehicle_type         10.59\n",
       "fuel_type             9.29\n",
       "registration_year     6.83\n",
       "gearbox               5.60\n",
       "model                 5.56\n",
       "price                 0.00\n",
       "mileage               0.00\n",
       "brand                 0.00\n",
       "postal_code           0.00\n",
       "age                   0.00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find percentage of null values\n",
    "round(df.isnull().sum().sort_values(ascending = False) * 100/len(df),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Horse Power\n",
    "\n",
    "Horse power values can be filled with the average that a particular brand and model of car holds. However, models that are listed as 'other' can contain a range of different cars and will be excluded from the process.\n",
    "\n",
    "Filling will occur by concatenating brand and model columns. This is important because doing this by model only would lump all models classified as `other` as well as brands with exact models names. Those that are considered `other` will also be excluded by replacing these values with null values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine brand and model columns\n",
    "df['brand_model'] = df['brand'] + '_' + df['model'].replace('other', np.nan)\n",
    "\n",
    "# groupby brand_model and find median power\n",
    "median_power = df.groupby('brand_model')['power'].median()\n",
    "\n",
    "# where power is null, replace with median power of brand_model\n",
    "df['power'] = df['power'].fillna(df['brand_model'].map(median_power))\n",
    "\n",
    "# drop brand_model column\n",
    "df = df.drop('brand_model', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Values\n",
    "\n",
    "Some missing data columns include an option for `other` already. These include:\n",
    "\n",
    "- model\n",
    "- vehicle type\n",
    "- fuel type\n",
    "\n",
    "Null values in these columns will also be set accordingly.\n",
    "\n",
    "\n",
    "\n",
    "Also fill 'not_repaired' values as `other` as these values make up a large chunk of the data that should not be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill null values in columns with 'other' as an option\n",
    "df['model'] = df['model'].fillna('other')\n",
    "df['vehicle_type'] = df['vehicle_type'].fillna('other')\n",
    "df['fuel_type'] = df['fuel_type'].fillna('other')\n",
    "\n",
    "# fill null values in not_repaired column with 'other'\n",
    "df['not_repaired'] = df['not_repaired'].fillna('other')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine Remaining Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "registration_year    6.83\n",
       "gearbox              5.60\n",
       "power                2.69\n",
       "price                0.00\n",
       "vehicle_type         0.00\n",
       "model                0.00\n",
       "mileage              0.00\n",
       "fuel_type            0.00\n",
       "brand                0.00\n",
       "not_repaired         0.00\n",
       "postal_code          0.00\n",
       "age                  0.00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find percentage of null values\n",
    "round(df.isnull().sum().sort_values(ascending = False) * 100/len(df),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop remaining null values as only a small percentage remains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows with null values\n",
    "df = df.dropna()\n",
    "\n",
    "# reset index\n",
    "df = df.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing Data\n",
    "\n",
    "### Encoding\n",
    "\n",
    "Data encoding ensures models recognise data in the appropriate way. However, different models recognise data differently. Theoretically, all could be done using OHC, but to reduce high dimensionality effects (increased training time, overfitting), each will be encoded differently for linear regression, random forest and gradient boosting models.\n",
    "\n",
    "One hot encoding is appropriate for linear regression, whereas label encoding will be more appropriate for the random forest regressor. Gradient boosting does not require encoding as they have systems inbuilt that can handle this data, however, requires datatype changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Encoding for Linear Regression\n",
    "\n",
    "OHE assigns a new column for each unique value in categorical columns. In this case this includes values from:\n",
    "\n",
    "- `vehicle_type`\n",
    "- `gearbox`\n",
    "- `model`\n",
    "- `fuel_type`\n",
    "-`brand`\n",
    "-`not_repaired`\n",
    "\n",
    "Each will be "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(308999, 315)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply one hot encoding to categorical columns\n",
    "one_hot = OneHotEncoder()\n",
    "\n",
    "# fit one hot encoder to categorical columns\n",
    "one_hot.fit(df[categorical])\n",
    "\n",
    "# transform categorical columns\n",
    "one_hot_arr = one_hot.transform(df[categorical]).toarray()\n",
    "\n",
    "# create dataframe of one hot encoded columns\n",
    "one_hot_df = pd.DataFrame(one_hot_arr, columns=one_hot.get_feature_names_out())\n",
    "\n",
    "# drop categorical columns from original dataframe\n",
    "df_ohe = df.drop(categorical, axis = 1)\n",
    "\n",
    "# left merge one hot encoded dataframe with original dataframe\n",
    "df_ohe = df_ohe.merge(one_hot_df, left_index=True, right_index=True)\n",
    "\n",
    "# confirm shape length matches original dataframe\n",
    "df_ohe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(308999, 315)\n"
     ]
    }
   ],
   "source": [
    "# create copy of df for ohe\n",
    "df_ohe = df.copy()\n",
    "\n",
    "# identify categorical columns\n",
    "categorical = df_ohe.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# apply one hot encoding to categorical columns\n",
    "encoder = OneHotEncoder()\n",
    "one_hot_encoded = encoder.fit_transform(df_ohe[categorical])\n",
    "\n",
    "# convert the one hot encoded result into a DataFrame\n",
    "one_hot_df = pd.DataFrame(one_hot_encoded.toarray(), columns=encoder.get_feature_names_out(categorical))\n",
    "\n",
    "# drop categorical columns from original dataframe\n",
    "df_ohe = df_ohe.drop(categorical, axis=1)\n",
    "\n",
    "# left merge one hot encoded dataframe with original dataframe\n",
    "df_ohe = pd.concat([df_ohe, one_hot_df], axis=1)\n",
    "\n",
    "# confirm shape length matches original dataframe\n",
    "print(df_ohe.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Encoding for Random Forests\n",
    "\n",
    "Apply label encoding for categorical columns. This is done with OrdinalEncoder, but note that values are nominal.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(308999, 12)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a copy of original dataframe\n",
    "data_ordinal = df.copy()\n",
    "\n",
    "# apply ordinal encoding to categorical columns\n",
    "encoder = OrdinalEncoder()\n",
    "\n",
    "# fit ordinal encoder to categorical columns\n",
    "data_ordinal[categorical] = encoder.fit_transform(data_ordinal[categorical])\n",
    "\n",
    "#confirm shape length matches original dataframe\n",
    "data_ordinal.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Type Changing for Gradient Boosting Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 308999 entries, 0 to 308998\n",
      "Data columns (total 12 columns):\n",
      " #   Column             Non-Null Count   Dtype   \n",
      "---  ------             --------------   -----   \n",
      " 0   price              308999 non-null  int64   \n",
      " 1   vehicle_type       308999 non-null  category\n",
      " 2   registration_year  308999 non-null  float64 \n",
      " 3   gearbox            308999 non-null  category\n",
      " 4   power              308999 non-null  float64 \n",
      " 5   model              308999 non-null  category\n",
      " 6   mileage            308999 non-null  int64   \n",
      " 7   fuel_type          308999 non-null  category\n",
      " 8   brand              308999 non-null  category\n",
      " 9   not_repaired       308999 non-null  category\n",
      " 10  postal_code        308999 non-null  int64   \n",
      " 11  age                308999 non-null  int64   \n",
      "dtypes: category(6), float64(2), int64(4)\n",
      "memory usage: 16.2 MB\n"
     ]
    }
   ],
   "source": [
    "# convert category columns with object type to category type\n",
    "\n",
    "# create copy of dataframe for gradient boosting as df_gb\n",
    "df_gb = df.copy()\n",
    "\n",
    "# convert category features to category type\n",
    "for feature in categorical:\n",
    "    df_gb[feature] = pd.Series(df_gb[feature], dtype=\"category\")\n",
    "    \n",
    "# show info of df_gb\n",
    "df_gb.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training\n",
    "\n",
    "Now that the data has been pre-processed, models will be trained. Functions will be made that:\n",
    "\n",
    "1. split the data into training, validation and testing.\n",
    "2. split features from targets\n",
    "\n",
    "Once done models will be trained with fine-tuned hyperparameters that will give the best result. These results will include the root of the mean of squared errors (rmse) which be used to compare the four models. The linear regression model will be tested first and used as a baseline as this model has limited hyperparameters.\n",
    "\n",
    "## Linear Regression\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, Validation and Test\n",
    "\n",
    "As no test data has been provided, data will be split into train, validation and test sets. This will occur in a 60:20:20 ratio split. To do so first split the data by 60:40 (train:validation and test). Then split the validation and test portion 50:50.\n",
    "\n",
    "### Features and Targets\n",
    "\n",
    "Within the same function, split each dataset into features and targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function that splits data into sets and by features/targets\n",
    "def split_data(df):\n",
    "    # split into train, validation, and test sets\n",
    "    train, val_test = train_test_split(df, test_size = 0.4, random_state = 42)\n",
    "    val, test = train_test_split(val_test, test_size = 0.5, random_state = 42)\n",
    "    \n",
    "    # split into features and targets\n",
    "    features_train, target_train = train.drop('price', axis = 1), train['price']\n",
    "    features_val, target_val = val.drop('price', axis = 1), val['price']\n",
    "    features_test, target_test = test.drop('price', axis = 1), test['price']\n",
    "    \n",
    "    return features_train, target_train, features_val, target_val, features_test, target_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data_ohe for linear regression\n",
    "features_train_ohe, target_train_ohe, features_val_ohe, \\\n",
    "target_val_ohe, features_test_ohe, target_test_ohe = split_data(df_ohe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Predictions and RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 2665.65\n",
      "Model training time: 4.61 seconds\n",
      "Model prediction time: 0.06 seconds\n",
      "Total execution time: 4.67 seconds\n"
     ]
    }
   ],
   "source": [
    "# start time\n",
    "start_time = time.time()\n",
    "\n",
    "# train the model\n",
    "model = LinearRegression()\n",
    "\n",
    "# model training time start\n",
    "model_training_start = time.time()\n",
    "\n",
    "# fit the model\n",
    "model.fit(features_train_ohe, target_train_ohe)\n",
    "\n",
    "# model training time end\n",
    "model_training_end = time.time()\n",
    "\n",
    "# make predictions\n",
    "predictions = model.predict(features_val_ohe)\n",
    "\n",
    "# model prediction time end\n",
    "model_prediction_end = time.time()\n",
    "\n",
    "# calculate RMSE\n",
    "rmse = mean_squared_error(target_val_ohe, predictions) ** 0.5\n",
    "\n",
    "# print RMSE\n",
    "print('RMSE:', round(rmse,2))\n",
    "\n",
    "# calculate execution time\n",
    "execution_time = model_prediction_end - start_time  # Calculate execution time\n",
    "\n",
    "# print execution time\n",
    "print('Model training time:', round(model_training_end - model_training_start,2),'seconds')\n",
    "print('Model prediction time:', round(model_prediction_end - model_training_end,2),'seconds')\n",
    "print('Total execution time:', round(execution_time,2),'seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Regressor\n",
    "\n",
    "The random forest regressor will follow a similar process. Key differences will include using the label encoded dataframe and using more hyperparameters to find a more optimal RMSE value. Hyperparameters will be looped based on tree depth and number of estimators.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data_ordinal for linear regression\n",
    "features_train_ordinal, target_train_ordinal, features_val_ordinal, \\\n",
    "target_val_ordinal, features_test_ordinal, target_test_ordinal = split_data(data_ordinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1781.69\n",
      "n_estimators: 70\n",
      "max_depth: 12\n",
      "Training time: 21.85533094406128\n",
      "Prediction time: 0.32674503326416016\n",
      "Totatl execution time: 395.01 seconds\n"
     ]
    }
   ],
   "source": [
    " # Record start time\n",
    "start_time = time.time()\n",
    "\n",
    "# set hyperparameters\n",
    "n_estimators = range(30, 71, 10)\n",
    "max_depth = range(7, 13, 1)\n",
    "\n",
    "# best rmse score (set high to start)\n",
    "best_rmse = 10000\n",
    "\n",
    "# loop through hyperparameters\n",
    "for n in n_estimators:\n",
    "    for d in max_depth:\n",
    "        # start training time\n",
    "        start_train_time = time.time()\n",
    "        \n",
    "        # train the model\n",
    "        model = RandomForestRegressor(random_state=42, n_estimators=n, max_depth=d)\n",
    "        \n",
    "        # fit the model\n",
    "        model.fit(features_train_ordinal, target_train_ordinal)\n",
    "        \n",
    "        # end train time\n",
    "        end_train_time = time.time()\n",
    "\n",
    "        # make predictions\n",
    "        predictions = model.predict(features_val_ordinal)\n",
    "        \n",
    "        # end prediction time\n",
    "        end_prediction_time = time.time()\n",
    "\n",
    "        # calculate RMSE\n",
    "        rmse = mean_squared_error(target_val_ordinal, predictions) ** 0.5\n",
    "\n",
    "        # if rmse is lower than best_rmse, update best_rmse\n",
    "        if rmse < best_rmse:\n",
    "            best_rmse = rmse\n",
    "            best_n = n\n",
    "            best_d = d\n",
    "            training_time = end_train_time - start_train_time\n",
    "            predictions_time = end_prediction_time - end_train_time\n",
    "\n",
    "# end time\n",
    "end_time = time.time()\n",
    "\n",
    "# find hyperparameter time\n",
    "hyperparameter_time = end_time - start_time\n",
    "\n",
    "# calculate execution time\n",
    "execution_time = end_time - start_time  # Calculate total execution time\n",
    "            \n",
    "# print best hyperparameters\n",
    "print('RMSE:', round(best_rmse,2))\n",
    "print('n_estimators:', best_n)\n",
    "print('max_depth:', best_d)\n",
    "print('Training time:', round(training_time,2), 'seconds')\n",
    "print('Prediction time:', round(predictions_time,2), 'seconds')\n",
    "print('Total execution time:', round(hyperparameter_time,2), 'seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting\n",
    "\n",
    "Gradient boosting will use LightGBM and CatBoost models. Both will use the same data which will be split from the `df_gb` dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "features_train_gb, target_train_gb, features_val_gb, \\\n",
    "target_val_gb, features_test_gb, target_test_gb = split_data(df_gb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Light GBM\n",
    "\n",
    "Hyperparameters that will be looped over include number of leaves, tree depth and learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1586.68\n",
      "Best hyperparameters: {'num_leaves': 80, 'max_depth': 10, 'learning_rate': 0.1}\n",
      "Training time: 8.03 seconds\n",
      "Prediction time: 0.59 seconds\n",
      "Total execution time for all hyperparameters: 15368.14 seconds\n"
     ]
    }
   ],
   "source": [
    "# Set high RMSE to start\n",
    "best_rmse = 10000\n",
    "\n",
    "# Set best hyperparameters\n",
    "best_params = {'num_leaves': None, 'max_depth': None, 'learning_rate': None}\n",
    "\n",
    "# Set hyperparameters\n",
    "n_leaves = range(50, 91, 10)\n",
    "depth = range(7, 13, 1)\n",
    "learning_rate = [0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "\n",
    "# Record start time\n",
    "start_time = time.time()\n",
    "\n",
    "# Loop through hyperparameters\n",
    "for num_leaves in n_leaves:\n",
    "    for max_depth in depth:\n",
    "        for lr in learning_rate:\n",
    "            # Define parameters\n",
    "            params = {\n",
    "                'task': 'train', \n",
    "                'boosting': 'gbdt',\n",
    "                'objective': 'regression',\n",
    "                'num_leaves': num_leaves,\n",
    "                'max_depth': max_depth,\n",
    "                'verbose': -1,\n",
    "                'metric': 'rmse',\n",
    "                'learning_rate': lr,\n",
    "            }\n",
    "\n",
    "            # start training time\n",
    "            start_train_time = time.time()\n",
    "\n",
    "            # load data into LightGBM dataset\n",
    "            lgb_train = lgb.Dataset(features_train_gb, target_train_gb)\n",
    "        \n",
    "            # fit the model\n",
    "            model = lgb.train(params, lgb_train, num_boost_round=1000)\n",
    "            \n",
    "            # end train time\n",
    "            end_train_time = time.time()\n",
    "\n",
    "            # make predictions\n",
    "            predictions = model.predict(features_val_gb, num_iteration=model.best_iteration)\n",
    "            \n",
    "            # end prediction time\n",
    "            end_prediction_time = time.time()\n",
    "\n",
    "            # calculate RMSE\n",
    "            rmse = mean_squared_error(target_val_gb, predictions) ** 0.5\n",
    "\n",
    "            # If RMSE is lower than best_rmse, update best_rmse and best_params\n",
    "            if rmse < best_rmse:\n",
    "                best_rmse = rmse\n",
    "                best_params['num_leaves'] = num_leaves\n",
    "                best_params['max_depth'] = max_depth\n",
    "                best_params['learning_rate'] = lr\n",
    "                best_time = time.time() - start_time\n",
    "                training_time = end_train_time - start_train_time\n",
    "                predictions_time = end_prediction_time - end_train_time\n",
    "                \n",
    "\n",
    "# Print rmse and best hyperparameters\n",
    "print('RMSE:', round(best_rmse, 2))\n",
    "print('Best hyperparameters:', best_params)\n",
    "\n",
    "# print execution times\n",
    "print('Training time:', round(training_time, 2), 'seconds')\n",
    "print('Prediction time:', round(predictions_time, 2), 'seconds')\n",
    "print('Total execution time for all hyperparameters:', round(time.time() - start_time, 2), 'seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.24868\n",
      "0:\tlearn: 3867.3992240\ttotal: 97.9ms\tremaining: 29.3s\n",
      "20:\tlearn: 1899.0404320\ttotal: 767ms\tremaining: 10.2s\n",
      "40:\tlearn: 1814.0047265\ttotal: 1.44s\tremaining: 9.11s\n",
      "60:\tlearn: 1763.4937535\ttotal: 2.13s\tremaining: 8.33s\n",
      "80:\tlearn: 1734.8414802\ttotal: 2.76s\tremaining: 7.45s\n",
      "100:\tlearn: 1714.7022312\ttotal: 3.36s\tremaining: 6.62s\n",
      "120:\tlearn: 1699.4839566\ttotal: 4.05s\tremaining: 5.99s\n",
      "140:\tlearn: 1686.5864089\ttotal: 4.74s\tremaining: 5.35s\n",
      "160:\tlearn: 1673.1592576\ttotal: 5.51s\tremaining: 4.76s\n",
      "180:\tlearn: 1661.5575040\ttotal: 6.33s\tremaining: 4.16s\n",
      "200:\tlearn: 1650.3172890\ttotal: 6.94s\tremaining: 3.42s\n",
      "220:\tlearn: 1643.1304999\ttotal: 7.57s\tremaining: 2.71s\n",
      "240:\tlearn: 1634.5835119\ttotal: 8.17s\tremaining: 2s\n",
      "260:\tlearn: 1626.9940590\ttotal: 8.79s\tremaining: 1.31s\n",
      "280:\tlearn: 1619.6881842\ttotal: 9.44s\tremaining: 638ms\n",
      "299:\tlearn: 1612.7646550\ttotal: 10s\tremaining: 0us\n",
      "RMSE: 1660.48\n",
      "Training time: 10.31 seconds\n",
      "Prediction time: 0.05 seconds\n",
      "Total execution time: 10.37 seconds\n"
     ]
    }
   ],
   "source": [
    "# record start time\n",
    "start_time = time.time() \n",
    "\n",
    "# initialize CatBoostRegressor with appropriate parameters\n",
    "model = CatBoostRegressor(loss_function='RMSE', iterations=300, random_seed=42)\n",
    "\n",
    "# create list of categorical features\n",
    "cat_features = ['vehicle_type', 'gearbox', 'model', 'fuel_type', 'brand', 'not_repaired']\n",
    "\n",
    "# start training time\n",
    "start_train_time = time.time()\n",
    "\n",
    "# fit the model\n",
    "model.fit(features_train_gb, target_train_gb, cat_features=cat_features, verbose=20)\n",
    "\n",
    "# end training time\n",
    "end_train_time = time.time()\n",
    "\n",
    "# make predictions\n",
    "predictions = model.predict(features_val_gb)\n",
    "\n",
    "# end prediction time\n",
    "end_prediction_time = time.time()\n",
    "\n",
    "# calculate RMSE\n",
    "rmse = mean_squared_error(target_val_gb, predictions) ** 0.5\n",
    "\n",
    "# print RMSE\n",
    "print('RMSE:', round(rmse, 2))\n",
    "\n",
    "# record end time\n",
    "end_time = time.time()\n",
    "\n",
    "# calculate execution time\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "# print execution time\n",
    "print('Training time:', round(end_train_time - start_train_time, 2), 'seconds')\n",
    "print('Prediction time:', round(end_prediction_time - end_train_time, 2), 'seconds')\n",
    "print('Total execution time:', round(execution_time, 2), 'seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression\n",
    "Linear regression shows a large RMSE value at 2666 that was calculated in just under 5 seconds. This indicates that this model may not be that accurate, however, acts as a baseline for the other models.\n",
    "\n",
    "## Random Forest\n",
    "The random forest model was tested next and provided a much better RMSE value at around 1782. However, iterating through these hyperparameters took almost 7 minutes to find the best model. This model itself took just over 22 seconds to train. Once trained, predictions were made within 0.33 seconds.\n",
    "\n",
    "## Gradient Descent \n",
    "The light GBM generated an even better RMSE value at 1587 and at a quicker rate that trained and predicted values in around 9 seconds. However, more time was spent to find the best parameters at around 19 minutes.\n",
    "\n",
    "The CatBoost model also performed better than the random forest model. However, RMSE (1660) and total execution time (10.37 seconds) were just behind the light GBM model.\n",
    "\n",
    "\n",
    "## Analysis\n",
    "Overall, the light GBM provided the best results in terms of RMSE and speed.\n",
    "\n",
    "## Final Predictions\n",
    "Now that this model has been chosen, predictions will be made on the test set using the appropriate parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1623.92\n",
      "Training time: 8.6 seconds\n",
      "Prediction time: 0.72 seconds\n"
     ]
    }
   ],
   "source": [
    "# Define parameters\n",
    "params = {\n",
    "    'task': 'train', \n",
    "    'boosting': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'num_leaves': 80,\n",
    "    'max_depth': 10,\n",
    "    'verbose': -1,\n",
    "    'metric': 'rmse',\n",
    "    'learning_rate': 0.1,\n",
    "}\n",
    "\n",
    "# start training time\n",
    "start_train_time = time.time()\n",
    "\n",
    "# load data into LightGBM dataset\n",
    "lgb_train = lgb.Dataset(features_train_gb, target_train_gb)\n",
    "\n",
    "# fit the model\n",
    "model = lgb.train(params, lgb_train, num_boost_round=1000)\n",
    "\n",
    "# end train time\n",
    "end_train_time = time.time()\n",
    "\n",
    "# make predictions\n",
    "predictions = model.predict(features_test_gb, num_iteration=model.best_iteration)\n",
    "\n",
    "# end prediction time\n",
    "end_prediction_time = time.time()\n",
    "\n",
    "# calculate RMSE\n",
    "rmse = mean_squared_error(target_test_gb, predictions) ** 0.5\n",
    "\n",
    "# training time\n",
    "training_time = end_train_time - start_train_time\n",
    "\n",
    "# prediction time\n",
    "predictions_time = end_prediction_time - end_train_time\n",
    "\n",
    "# print rmse\n",
    "print('RMSE:', round(rmse, 2))\n",
    "\n",
    "# print execution times\n",
    "print('Training time:', round(training_time, 2), 'seconds')\n",
    "print('Prediction time:', round(predictions_time, 2), 'seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "\n",
    "The RMSE value is similar to the RMSE value higher than the validation set, yet still better than any other model when compared to validation stages. The execution time is also reasonably similar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "### Accuracy\n",
    "\n",
    "A gradient boosting model (LGBM) performed best among other models, achieving an RMSE of 1586.68. This indicates that, on average, the predicted car values deviate from the true values by approximately `$1,586`. This compares to RMSE values of 1660, 1781.69, and 2665.65 of the CatBoost, Random Forest, and Linear Regression models.\n",
    "\n",
    "### Speed\n",
    "\n",
    "To train the LGBM model, training time was minimal at 8.03 seconds which is faster than the CatBoost (10.31 seconds) and Random Forest (21.86 seconds) models. The Linear Regression model was faster, however, much more inaccurate.\n",
    "\n",
    "### Test Set\n",
    "\n",
    "When applying the LGBM model to the test set, RMSE decreased slightly to 1623.92 but retained a faster training time at 8.6 seconds. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qtconsole",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
