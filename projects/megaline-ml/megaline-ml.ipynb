{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Megaline Plan Prediction Model\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Mobile carrier Megaline has found out that many of their subscribers use legacy plans. They want to develop a model that would analyze subscribers' behavior and recommend one of Megaline's newer plans: Smart or Ultra. \n",
    "\n",
    "### Purpose\n",
    "\n",
    "Develop the best model that recommends the more applicable phone plan with 75% accuracy on a test set.\n",
    "\n",
    "### Data Description\n",
    "\n",
    "Every observation in the dataset contains monthly behavior information about one user. The information given is as follows:\n",
    "\n",
    "`calls:` Number of calls\n",
    "\n",
    "`minutes:` Total call duration in minutes\n",
    "\n",
    "`messages:` number of text messages\n",
    "\n",
    "`mb_used:` Internet traffic used in MB\n",
    "\n",
    "`is_ultra:` plan for the current month (Ultra - 1, Smart - 0)\n",
    "\n",
    "### Process\n",
    "\n",
    "The following steps will be made:\n",
    "- Read and Check Data\n",
    "- Split Data\n",
    "- Train Models:\n",
    "    - Decision Trees\n",
    "    - Random Forests\n",
    "    - Logistic Regression\n",
    "- Create Sanity Check\n",
    "- Make Conclusions\n",
    "\n",
    "## Read and Check Data\n",
    "\n",
    "As the dataset has already been cleaned in the statistical data analysis project, the data will only quickly be checked for missing values and duplicates. Notes on the type of task will also be made.\n",
    "\n",
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant packages\n",
    "import pandas as pd # to save dataframe\n",
    "from sklearn.model_selection import train_test_split # to split data into training and testing sets\n",
    "from sklearn.tree import DecisionTreeClassifier # to train model with decision tree\n",
    "from sklearn.ensemble import RandomForestClassifier # to train model with random forest\n",
    "from sklearn.linear_model import LogisticRegression # to train model with logistic regression\n",
    "from sklearn.metrics import accuracy_score # to calculate accuracy score\n",
    "import warnings # to ignore warnings\n",
    "from sklearn.dummy import DummyClassifier # to train model with dummy classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Dataframe\n",
    "Use pandas to read the users_behavior.csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.0</td>\n",
       "      <td>311.90</td>\n",
       "      <td>83.0</td>\n",
       "      <td>19915.42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85.0</td>\n",
       "      <td>516.75</td>\n",
       "      <td>56.0</td>\n",
       "      <td>22696.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77.0</td>\n",
       "      <td>467.66</td>\n",
       "      <td>86.0</td>\n",
       "      <td>21060.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>106.0</td>\n",
       "      <td>745.53</td>\n",
       "      <td>81.0</td>\n",
       "      <td>8437.39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66.0</td>\n",
       "      <td>418.74</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14502.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   calls  minutes  messages   mb_used  is_ultra\n",
       "0   40.0   311.90      83.0  19915.42         0\n",
       "1   85.0   516.75      56.0  22696.96         0\n",
       "2   77.0   467.66      86.0  21060.45         0\n",
       "3  106.0   745.53      81.0   8437.39         1\n",
       "4   66.0   418.74       1.0  14502.75         0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read csv file \n",
    "df = pd.read_csv('datasets/users_behavior.csv') \n",
    "\n",
    "# Show df head\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confirm Data is Clean\n",
    "\n",
    "#### Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     3214 non-null   float64\n",
      " 1   minutes   3214 non-null   float64\n",
      " 2   messages  3214 non-null   float64\n",
      " 3   mb_used   3214 non-null   float64\n",
      " 4   is_ultra  3214 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n"
     ]
    }
   ],
   "source": [
    "# Show info to check column types and null values\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This confirms that no null values exist.\n",
    "\n",
    "#### Duplicate Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for duplicates\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This confirms that no duplicate values exist.\n",
    "\n",
    "#### Unique Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_ultra\n",
       "0    2229\n",
       "1     985\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check is_ultra column to confirm only two unique values exist\n",
    "df['is_ultra'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only 0 and 1 are included in this column, correctly giving each value a plan designation. \n",
    "\n",
    "### Types and Subtypes\n",
    "\n",
    "#### Supervised Learning\n",
    "\n",
    "As both the features (calls, minutes, messages, mb_used) and target of plan type (ultra or smart) are given, the machine learning type will be supervised learning. This means an algorithym will use the features to determine the target value. \n",
    "\n",
    "#### Classification\n",
    "\n",
    "As the target is given in the form of a category, this will be a classification task. As the target only provides for two outcomes (ultra or smart), this will be a binary classification task.\n",
    "\n",
    "## Split Data\n",
    "\n",
    "As we do not have a test set, the data will be split into 3 parts. These are for the training, validation and test sets. This split will occur in a 3:1:1 ratio. This split is ideal as it keeps the validation and the test sets at the same size.\n",
    "\n",
    "We can do this by first splitting the data in a 3:2 ratio to give two datasets. The first will serve as the test set. The second will be split again in 1:1 ratio to give the validation and test sets.\n",
    "\n",
    "Once this done, the datasets will be split into features and target.\n",
    "\n",
    "### Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and validation with test \n",
    "df_train, df_valid_test = train_test_split(df, test_size=0.4, random_state=12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split df_valid_test into validation and test\n",
    "df_valid, df_test = train_test_split(df_valid_test, test_size=0.5, random_state=12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into Features and Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the training data into features and target\n",
    "features_train = df_train.drop(['is_ultra'], axis=1)\n",
    "target_train = df_train['is_ultra']\n",
    "\n",
    "# Split the validation data into features and target\n",
    "features_valid = df_valid.drop(['is_ultra'], axis=1)\n",
    "target_valid = df_valid['is_ultra']\n",
    "\n",
    "# Split the test data into features and target\n",
    "features_test = df_test.drop(['is_ultra'], axis=1)\n",
    "target_test = df_test['is_ultra']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train size: (1928, 5)\n",
      "x_test size: (643, 5)\n",
      "x_val size: (643, 5)\n"
     ]
    }
   ],
   "source": [
    "# Confirm the size of splitted data sets\n",
    "print('x_train size:', df_train.shape)\n",
    "print('x_test size:', df_test.shape)\n",
    "print('x_val size:', df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Testing\n",
    "\n",
    "Now that the sets are split, 3 different models will be tested. These include:\n",
    "\n",
    "1. Decision Trees\n",
    "2. Random Forests\n",
    "3. Logistic Regression\n",
    "\n",
    "Each will be tested. Hyperparameters will be set and iterated to find the best model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees\n",
    "\n",
    "#### Description\n",
    "\n",
    "Decision trees attempt to simplify the problem by creating binomial options at multiple levels. For instance, the decision tree might first classify a user's messaging habits as high or low by setting a certain messaging threshold. If this is low, a follow up may look to a users internet usage. \n",
    "\n",
    "Where internet usage and messaging habits are both low, the user may have a higher chance of holding a plan that has tighter limits.  However, the decision tree may go another level deeper and look to the number of phone calls a user might use. \n",
    "\n",
    "#### Hyperparameters\n",
    "\n",
    "`max_depth`: The maximum number of levels a decision tree will go. \n",
    "\n",
    "`random_state`: Allows for experiment consistency by assigning a random state. '12345' will be used.\n",
    "\n",
    "By iterating through a number of depth levels and checking the accuracy of the model at each point, an optimal depth can be found. This will be done in the context of megaline phone users to find the best decision tree model. A random state '12345' will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the best model: 78.54 %\n",
      "Found with a depth of: 3\n"
     ]
    }
   ],
   "source": [
    "# Find the best accuracy score for the model with accomodating max_depth\n",
    "# Save the best model and its result as best_model and best_result\n",
    "best_result = 0\n",
    "best_model = None\n",
    "\n",
    "# Create loop to find the best accuracy score with different max_depths\n",
    "for depth in range(1, 6):\n",
    "\tmodel = DecisionTreeClassifier(random_state=12345, max_depth= depth) # create a model with the given depth\n",
    "\tmodel.fit(features_train, target_train) # train the model\n",
    "\tpredictions = model.predict(features_valid) # get the model's predictions\n",
    "\tresult = accuracy_score(target_valid, predictions) # calculate accuracy against the validation set\n",
    "\tif result > best_result: # if the result is better than the previous best, save the model and its result\n",
    "\t\tbest_model = model\n",
    "\t\tbest_result = result\n",
    "     \n",
    "print(\"Accuracy of the best model:\", round(best_result*100,2), \"%\")\n",
    "print(\"Found with a depth of:\", best_model.max_depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "\n",
    "#### Description\n",
    "A random forest is another learning algorithym. It trains groups of independent trees and makes decisions based on majority class prediction.\n",
    "\n",
    "#### Hyperparameters\n",
    "\n",
    "`max_depth`: Like with decision trees, depth will be iterated for values 1 to 10.\n",
    "\n",
    "`n_estimators`: The number of trees that are built before voting takes place. This will be iterated from 10 to 50. \n",
    "\n",
    "`random_state`: '12345' will be used.\n",
    "\n",
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the best model: 80.87 %\n",
      "Found with 40 estimators and a depth of 8\n"
     ]
    }
   ],
   "source": [
    "# Find the best accuracy score for the model with accomodating max_depth and n_estimators\n",
    "best_score = 0\n",
    "best_est = 0\n",
    "best_depth = 0\n",
    "\n",
    "# Create loop to find the best accuracy score with different max_depths and n_estimators\n",
    "for est in range(10, 51): # choose hyperparameter range\n",
    "    for depth in range(1, 11):\n",
    "        model = RandomForestClassifier(max_depth=depth, random_state=12345, n_estimators=est) # set number of trees\n",
    "        model.fit(features_train, target_train) # train model on training set\n",
    "        score = model.score(features_valid, target_valid) # calculate accuracy score on validation set\n",
    "        if score > best_score: # if accuracy score is better than previous best, save model and its accuracy score\n",
    "            best_score = score\n",
    "            best_est = est\n",
    "            best_depth = depth\n",
    "\n",
    "print(\"Accuracy of the best model:\", round(best_score*100,2), \"%\")\n",
    "print(\"Found with\",best_est, \"estimators and a depth of\", best_depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "\n",
    "#### Description\n",
    "\n",
    "Logistic regression may be used by assigning observations of features (calls, messages, usage, etc) as either positive or negative (Ultra or Smart plans) based on probability.\n",
    "\n",
    "##### Parameters\n",
    "\n",
    "`solver`: Sets the method for fitting the data. Each will be used and compared.\n",
    "\n",
    "`random_state`: '12345' will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solver: newton-cg\n",
      "Accuracy on the validation set: 75.6 %\n",
      "\n",
      "Solver: lbfgs\n",
      "Accuracy on the validation set: 75.6 %\n",
      "\n",
      "Solver: liblinear\n",
      "Accuracy on the validation set: 70.8 %\n",
      "\n",
      "Solver: sag\n",
      "Accuracy on the validation set: 70.6 %\n",
      "\n",
      "Solver: saga\n",
      "Accuracy on the validation set: 70.6 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Save solvers to a list\n",
    "solvers = ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "\n",
    "# Create a loop to find the best accuracy score with different solvers\n",
    "for solver in solvers:\n",
    "    # Ignore warnings\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter('ignore')\n",
    "        \n",
    "        # Train model\n",
    "        model = LogisticRegression(random_state=12345, solver=solver)\n",
    "        model.fit(features_train, target_train)\n",
    "        score_valid = round(model.score(features_valid, target_valid), 3) * 100\n",
    "        print('Solver:', solver)\n",
    "        print('Accuracy on the validation set:', score_valid, '%')\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of these models, the Newton-CG solver provides for the best accuracy at 75.6%.\n",
    "\n",
    "## Model Quality\n",
    "\n",
    "The best model will take into account both accuracy and fit. \n",
    "\n",
    "### Accuracy\n",
    "\n",
    "The random forest had the best accuracy on the validation set at 80.87%. This is followed by the decision tree at 78.54% and lastly with logistic regression. \n",
    "\n",
    "### Fitting\n",
    "\n",
    "Models may accurately fit data to the training data, but fail to do so with the validation and set tests. This is particularly true for decision tree models. \n",
    "\n",
    "Random forests and logistic regression models handle this better. As the random forest for this project has a higher accuracy than the other models, the random forest model will be used. \n",
    "\n",
    "## Chosen Model: Random Forest\n",
    "\n",
    "As this is the chosen model, combine the training and validation sets to strengthen the model. Apply the model to the test data to determine final accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set: 79.9 %\n"
     ]
    }
   ],
   "source": [
    "# Combine training and validation sets\n",
    "features_train_valid = pd.concat([features_train, features_valid], axis=0)\n",
    "\n",
    "# Combine training and validation targets\n",
    "target_train_valid = pd.concat([target_train, target_valid], axis=0)\n",
    "\n",
    "# Train model on RandomForestClassifier with best hyperparameters\n",
    "model = RandomForestClassifier(max_depth=8, random_state=12345, n_estimators=40)\n",
    "\n",
    "# Train model on training and validation sets\n",
    "model.fit(features_train_valid, target_train_valid)\n",
    "\n",
    "# Calculate accuracy score on test set\n",
    "score_test = round(model.score(features_test, target_test), 3) * 100\n",
    "\n",
    "# Print accuracy score\n",
    "print('Accuracy on the test set:', score_test, '%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "\n",
    "Interestingly the accuracy has decreased, but is still above the 75% threshold.\n",
    "\n",
    "## Sanity Check\n",
    "\n",
    "A sanity check will be made to ensure that the model performs better than chance. To do so, a dummy classifier will be trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set: 48.0 %\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "model = DummyClassifier(strategy='uniform', random_state=12345)\n",
    "model.fit(features_train_valid, target_train_valid)\n",
    "\n",
    "# Calculate accuracy score on test set\n",
    "score_test = round(model.score(features_test, target_test), 2) * 100\n",
    "\n",
    "# Print accuracy score\n",
    "print('Accuracy on the test set:', score_test, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "\n",
    "The sanity check is passed a as the random model only garnered an accuracy of 48%, one that is much lower than that yielded by the random forest model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "### Dataset\n",
    "In summary, the data was loaded and confirmed to have been cleaned. Supervised learning on a binomial classification was determined as the appropriate type of task.\n",
    "\n",
    "### Split\n",
    "\n",
    "The data was split into training, validation and test sets in a 3:1:1 ratio. This split occurred as it is optimal to keep the validation and test sets similar in size.\n",
    "\n",
    "### Model Testing\n",
    "\n",
    "Three models were compared. This included decision trees, random forests, and logistic regression. Each were iterated using different parameters to find the optimal accuracy.\n",
    "\n",
    "### Model Quality\n",
    "\n",
    "Model quality was determined looking to accuracy and fitting. The random forests had the best accuracy and is not as subject to fitting as decision trees. Thus, the random forest model was chosen.\n",
    "\n",
    "### Chosen Model\n",
    "\n",
    "The random forest model was expanded by including the validation set. When testing, the random forest produced an accuracy of 79.9%.\n",
    "\n",
    "### Sanity Check\n",
    "\n",
    "To ensure the model is sufficient, a sanity check was made. A model that randomly assigned classes was created and garnered an accuracy of 48%. The sanity check is passed as this accuracy is much lower than the random trees model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
