{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OilyGiant's New Well Location\n",
    "\n",
    "## Introduction\n",
    "\n",
    "OilyGiant mining company is seeking the ideal place for a new oil well.\n",
    "\n",
    "The task will require:\n",
    "\n",
    " 1. Analyzing oil quality and volumes of different reserves. \n",
    " 2. Creating a model to predict the volume of reserves in new wells. \n",
    " \n",
    " This model will identify:\n",
    " \n",
    " 1. Oil wells with the highest estimated values \n",
    " 2. Regions with oil wells that produce high profit margins\n",
    "\n",
    "### Data Description\n",
    "\n",
    "Three datasets from oil samples within three regions have been provided in the datasets folder. For each the following parameters are given:\n",
    "\n",
    "`id:` unique oil well identifier\n",
    "\n",
    "`f0, f1, f2:` three undisclosed features of significance\n",
    "\n",
    "`product:` volume of reserves in the oil well (thousand barrels)\n",
    "\n",
    "Potential profits and risks will be identified using the bootstrapping method.\n",
    "\n",
    "### Procedure\n",
    "\n",
    "The process will include five distinct steps:\n",
    "1. Data Preparation\n",
    "2. Model training and testing\n",
    "3. Prepare data for profit calculation\n",
    "4. Calculate profit from a set of selected oil wells and model predictions\n",
    "5. Calculate risks and profit for each region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "Import packages and read in dataframes for each well. \n",
    "\n",
    "Check for:\n",
    "\n",
    "1. Data types\n",
    "2. Missing data\n",
    "3. Duplicate Data\n",
    "\n",
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import pandas as pd # for data processing\n",
    "from sklearn.model_selection import train_test_split # for splitting data\n",
    "from sklearn.linear_model import LinearRegression # for linear regression\n",
    "from sklearn.metrics import mean_squared_error # for error calculation\\\n",
    "from numpy.random import RandomState # for random state\n",
    "import numpy as np # for array operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframes\n",
    "df1 = pd.read_csv('datasets/geo_data_0.csv')\n",
    "df2 = pd.read_csv('datasets/geo_data_1.csv')\n",
    "df3 = pd.read_csv('datasets/geo_data_2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id        f0        f1        f2     product\n",
      "0  txEyH  0.705745 -0.497823  1.221170  105.280062\n",
      "1  2acmU  1.334711 -0.340164  4.365080   73.037750\n",
      "2  409Wp  1.022732  0.151990  1.419926   85.265647\n",
      "      id         f0        f1        f2     product\n",
      "0  kBEdx -15.001348 -8.276000 -0.005876    3.179103\n",
      "1  62mP7  14.272088 -3.475083  0.999183   26.953261\n",
      "2  vyE1P   6.263187 -5.948386  5.001160  134.766305\n",
      "      id        f0        f1        f2    product\n",
      "0  fwXo0 -1.146987  0.963328 -0.828965  27.758673\n",
      "1  WJtFt  0.262778  0.269839 -2.530187  56.069697\n",
      "2  ovLUW  0.194587  0.289035 -5.586433  62.871910\n"
     ]
    }
   ],
   "source": [
    "### Show first rows of each dataframe\n",
    "for i in [df1, df2, df3]:\n",
    "    print(i.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From quick inspection, the id column contains string values and the others are floats.\n",
    "\n",
    "### Data Types\n",
    "\n",
    "Data types of each column will be checked with 'info'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 5 columns):\n",
      " #   Column   Non-Null Count   Dtype  \n",
      "---  ------   --------------   -----  \n",
      " 0   id       100000 non-null  object \n",
      " 1   f0       100000 non-null  float64\n",
      " 2   f1       100000 non-null  float64\n",
      " 3   f2       100000 non-null  float64\n",
      " 4   product  100000 non-null  float64\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 3.8+ MB\n",
      "None \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 5 columns):\n",
      " #   Column   Non-Null Count   Dtype  \n",
      "---  ------   --------------   -----  \n",
      " 0   id       100000 non-null  object \n",
      " 1   f0       100000 non-null  float64\n",
      " 2   f1       100000 non-null  float64\n",
      " 3   f2       100000 non-null  float64\n",
      " 4   product  100000 non-null  float64\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 3.8+ MB\n",
      "None \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 5 columns):\n",
      " #   Column   Non-Null Count   Dtype  \n",
      "---  ------   --------------   -----  \n",
      " 0   id       100000 non-null  object \n",
      " 1   f0       100000 non-null  float64\n",
      " 2   f1       100000 non-null  float64\n",
      " 3   f2       100000 non-null  float64\n",
      " 4   product  100000 non-null  float64\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 3.8+ MB\n",
      "None \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check datatypes of each dataframe\n",
    "for i in [df1, df2, df3]:\n",
    "    print(i.info(), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each column is in the right format. \n",
    "\n",
    "### Missing Values\n",
    "\n",
    "From the above analysis, no missing values are present.\n",
    "\n",
    "### Duplicate Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "4\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicates within 'id' column\n",
    "for i in [df1, df2, df3]:\n",
    "    print(i.duplicated(subset='id').sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As duplicates exist, print each set within all dataframes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          id        f0        f1         f2     product\n",
      "66136  74z30  1.084962 -0.312358   6.990771  127.643327\n",
      "64022  74z30  0.741456  0.459229   5.153109  140.771492\n",
      "51970  A5aEY -0.180335  0.935548  -2.094773   33.020205\n",
      "3389   A5aEY -0.039949  0.156872   0.209861   89.249364\n",
      "69163  AGS9W -0.933795  0.116194  -3.655896   19.230453\n",
      "42529  AGS9W  1.454747 -0.479651   0.683380  126.370504\n",
      "931    HZww2  0.755284  0.368511   1.863211   30.681774\n",
      "7530   HZww2  1.061194 -0.373969  10.430210  158.828695\n",
      "63593  QcMuo  0.635635 -0.473422   0.862670   64.578675\n",
      "1949   QcMuo  0.506563 -0.323775  -2.215583   75.496502\n",
      "75715  Tdehs  0.112079  0.430296   3.218993   60.964018\n",
      "21426  Tdehs  0.829407  0.298807  -0.049563   96.035308\n",
      "92341  TtcGQ  0.110711  1.022689   0.911381  101.318008\n",
      "60140  TtcGQ  0.569276 -0.104876   6.440215   85.350186\n",
      "89582  bsk9y  0.398908 -0.400253  10.122376  163.433078\n",
      "97785  bsk9y  0.378429  0.005837   0.160827  160.637302\n",
      "41724  bxg6G -0.823752  0.546319   3.630479   93.007798\n",
      "1364   bxg6G  0.411645  0.856830  -3.653440   73.604260\n",
      "16633  fiKDv  0.157341  1.028359   5.585586   95.817889\n",
      "90815  fiKDv  0.049883  0.841313   6.394613  137.346586 \n",
      "\n",
      "          id         f0         f1        f2     product\n",
      "5849   5ltQ6  -3.435401 -12.296043  1.999796   57.085625\n",
      "84461  5ltQ6  18.213839   2.191999  3.993869  107.813044\n",
      "1305   LHZR0  11.170835  -1.945066  3.002872   80.859783\n",
      "41906  LHZR0  -8.989672  -4.286607  2.009139   57.085625\n",
      "2721   bfPNe  -9.494442  -5.463692  4.006042  110.992147\n",
      "82178  bfPNe  -6.202799  -4.820045  2.995107   84.038886\n",
      "47591  wt4Uk  -9.091098  -8.109279 -0.002314    3.179103\n",
      "82873  wt4Uk  10.259972  -9.376355  4.994297  134.766305 \n",
      "\n",
      "          id        f0        f1        f2     product\n",
      "45404  KUPhW  0.231846 -1.698941  4.990775   11.716299\n",
      "55967  KUPhW  1.211150  3.176408  5.543540  132.831802\n",
      "11449  VF7Jo  2.122656 -0.858275  5.746001  181.716817\n",
      "49564  VF7Jo -0.883115  0.560537  0.723601  136.233420\n",
      "44378  Vcm5J -1.229484 -2.439204  1.222909  137.968290\n",
      "95090  Vcm5J  2.587702  1.986875  2.482245   92.327572\n",
      "28039  xCHr8  1.633027  0.368135 -2.378367    6.120525\n",
      "43233  xCHr8 -0.847066  2.101796  5.597130  184.388641 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Find duplicates values in each dataframe\n",
    "for i in [df1, df2, df3]:\n",
    "    duplicates = (i[i.duplicated(subset='id', keep=False)])\n",
    "    duplicates = duplicates.sort_values(by='id')\n",
    "    print(duplicates, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From examination, each id has a unique value that is 5 characters long. However, the length of the data sets are 100,000. Perhaps these values are given due to random chance. This can be determined by finding the expected number of duplicates that would exist given the circumstances. Compare this value to the current number of duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of expected duplicate id numbers for each dataframe = 11\n"
     ]
    }
   ],
   "source": [
    "# Find the chances 'id' names are duplicated\n",
    "\n",
    "# Save options as zero\n",
    "options = 0\n",
    "\n",
    "# Calculate the number of options for each string element in the 'id' column\n",
    "for i in range(5):\n",
    "    if i == 0:\n",
    "        # Set options to the number of unique values of the first string element in the 'id' column \n",
    "        options = len(df1['id'].str[i].unique())\n",
    "        # Multiply by the number of the unique values of the remaining four string elements\n",
    "    else:\n",
    "        options *= len(df1['id'].str[i].unique())\n",
    "    \n",
    "# Calculate the chances of each 'id' name being duplicated\n",
    "chances = (100000 / options)\n",
    "\n",
    "# Expected chances of duplicates\n",
    "print('Number of expected duplicate id numbers for each dataframe =', round(100000 * chances))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As no dataset has more duplicates than the expected 11, they can be considered as a result of random chance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "\n",
    "Now data has been pre-processed, each region will be split into training and validation sets. Once split, the model can be trained. This will give predictions as to the average volume reserves. An analysis will select the largest volume reserve average."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data\n",
    "\n",
    "The data needs to be split in two ways for:\n",
    "1. Features and target\n",
    "2. Training and validation sets\n",
    "\n",
    "The second split will be done in a 75:25 ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Split data into training and validation.\n",
    "\n",
    "# Create function to split data\n",
    "def split_data(data):\n",
    "    # Split data into features and target\n",
    "    features = data.drop(['product', 'id'], axis=1)\n",
    "    target = data['product']\n",
    "    \n",
    "    # Split data into training and validation sets\n",
    "    features_train, features_valid, target_train, target_valid = train_test_split(features, target, test_size=0.25, random_state=12345)\n",
    "    \n",
    "    # Return the split data\n",
    "    return features_train, features_valid, target_train, target_valid\n",
    "    \n",
    "# Split data for each region\n",
    "features_train_1, features_valid_1, target_train_1, target_valid_1 = split_data(df1)\n",
    "features_train_2, features_valid_2, target_train_2, target_valid_2 = split_data(df2)\n",
    "features_train_3, features_valid_3, target_train_3, target_valid_3 = split_data(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df1 splits: \n",
      "Features train shape: (75000, 3) \n",
      "Features valid shape: (25000, 3) \n",
      "Target train shape: (75000,) \n",
      "Target valid shape: (25000,) \n",
      "\n",
      "df2 splits: \n",
      "Features train shape: (75000, 3) \n",
      "Features valid shape: (25000, 3) \n",
      "Target train shape: (75000,) \n",
      "Target valid shape: (25000,) \n",
      "\n",
      "df3 splits: Features train shape: (75000, 3) \n",
      " Features valid shape: (25000, 3) \n",
      " Target train shape: (75000,) \n",
      " Target valid shape: (25000,) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Confirm each set is the proper size (75% training, 25% validation)\n",
    "\n",
    "# Print shape of each set\n",
    "print('df1 splits:', '\\n'\n",
    "      'Features train shape:', features_train_1.shape, '\\n'\n",
    "      'Features valid shape:', features_valid_1.shape, '\\n'\n",
    "      'Target train shape:', target_train_1.shape, '\\n'\n",
    "      'Target valid shape:', target_valid_1.shape, '\\n')\n",
    "\n",
    "print('df2 splits:', '\\n'\n",
    "        'Features train shape:', features_train_2.shape, '\\n'\n",
    "        'Features valid shape:', features_valid_2.shape, '\\n'\n",
    "        'Target train shape:', target_train_2.shape, '\\n'\n",
    "        'Target valid shape:', target_valid_2.shape, '\\n')\n",
    "\n",
    "print('df3 splits:',\n",
    "        'Features train shape:', features_train_3.shape, '\\n',\n",
    "        'Features valid shape:', features_valid_3.shape, '\\n',\n",
    "        'Target train shape:', target_train_3.shape, '\\n',\n",
    "        'Target valid shape:', target_valid_3.shape, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model and Make Predictions\n",
    "\n",
    "As our target is numerical, linear regression will be used to train the model to:\n",
    "\n",
    "1. Train the model based on target and feature values from the training set\n",
    "2. Predict validation values based on the training set\n",
    "3. Calculate the average volume of predicted reserves\n",
    "4. Calculate the root square mean variable (RMSE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to predict volume and calculate RMSE\n",
    "def predicted_volume_rmse(features_train, features_valid, target_train, target_valid):\n",
    "    # Initialize model constructor\n",
    "    model = LinearRegression()\n",
    "    \n",
    "    # 1. Train model on training set\n",
    "    model.fit(features_train, target_train)\n",
    "    \n",
    "    # 2. Get model predictions on validation set\n",
    "    predictions_valid = model.predict(features_valid)\n",
    "    \n",
    "    # Save predictions as a series with index from target_valid\n",
    "    predictions_valid = pd.Series(predictions_valid, index=target_valid.index)\n",
    "    \n",
    "    # 3. Calclate volume reserve mean of predictions_valid\n",
    "    mean_predictions = predictions_valid.mean()\n",
    "    \n",
    "    # 4. Calculate RMSE on validation set\n",
    "    rmse = mean_squared_error(target_valid, predictions_valid) ** 0.5\n",
    "    \n",
    "    # Return RMSE\n",
    "    return round(rmse,2), round(mean_predictions,2), predictions_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Region 1 values: \n",
      "RMSE: 37.58 \n",
      "Predicted volume mean: 92.59 \n",
      "\n",
      "Region 2 values: \n",
      "RMSE: 0.89 \n",
      "Predicted volume mean: 68.73 \n",
      "\n",
      "Region 3 values: \n",
      "RMSE: 40.03 \n",
      "Predicted volume mean: 94.97\n"
     ]
    }
   ],
   "source": [
    "# Calculate region 1 data\n",
    "rmse_1, mean_predictions_1, predictions_valid_1 = predicted_volume_rmse(features_train_1, \n",
    "                                                                        features_valid_1, \n",
    "                                                                        target_train_1, \n",
    "                                                                        target_valid_1)\n",
    "print('Region 1 values:', '\\n'\n",
    "      'RMSE:', rmse_1, '\\n'\n",
    "      'Predicted volume mean:', mean_predictions_1, '\\n')\n",
    "\n",
    "# Calculate region 2 data\n",
    "rmse_2, mean_predictions_2, predictions_valid_2 = predicted_volume_rmse(features_train_2, \n",
    "                                                                        features_valid_2, \n",
    "                                                                        target_train_2, \n",
    "                                                                        target_valid_2)\n",
    "print('Region 2 values:', '\\n'\n",
    "      'RMSE:', rmse_2, '\\n'\n",
    "      'Predicted volume mean:', mean_predictions_2, '\\n')\n",
    "\n",
    "\n",
    "# Calculate region 3 data\n",
    "rmse_3, mean_predictions_3, predictions_valid_3 = predicted_volume_rmse(features_train_3, \n",
    "                                                                        features_valid_3, \n",
    "                                                                        target_train_3, \n",
    "                                                                        target_valid_3)\n",
    "print('Region 3 values:', '\\n'\n",
    "      'RMSE:', rmse_3, '\\n'\n",
    "      'Predicted volume mean:', mean_predictions_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of Results\n",
    "\n",
    "The third region has predicted the largest average of volume reserves at 94,970 barrels of oil. However, the root square mean square error is also the highest at 40.03, suggesting that higher variance also exists. This is followed by the first region with a slightly lower mean and RMSE. The second region is significantly lower in both categories with an impressively low RMSE at 0.89."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profit Calculation Preparation\n",
    "\n",
    "The profit calculation requires saving variables. A baseline oil volume value will also be calculated to determine the break even point. The formula can be expressed as:\n",
    "\n",
    "**required volume to breakeven = cost of single well / barrel price**\n",
    "\n",
    "Total cost is equal to the budget for 200 wells at `$100 million`. The cost of one well will divide the total cost by 200 wells. The barrel price of oil is `$4500`.\n",
    "\n",
    "Key values will first be saved according to the above formula. The calculation will then be made to determine how much each well must provide to break even. This value will be compared to the average of volume reserves in each region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store budget as $100 million for the total cost of the construction \n",
    "budget = 100000000\n",
    "\n",
    "# Divide budget by 200 to find budgets per well\n",
    "budget_per_well = budget / 200\n",
    "\n",
    "# Calculate revenue per unit of volume as $4,500\n",
    "revenue_per_unit = 4500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breakeven Production\n",
    "\n",
    "For a well to breakeven, the volume reserves revenue need to overcome the cost of the budget for an individual well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111.111\n"
     ]
    }
   ],
   "source": [
    "# Find breakeven volume\n",
    "breakeven = budget_per_well / revenue_per_unit\n",
    "\n",
    "print(round(breakeven, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Findings\n",
    "\n",
    "A well needs to contain atleast 111,111 barrels of oil in its reserves to atleast break even. The average predicted volume for each region is below this level. The third region is closest at 94,970 barrels. Yet, this is the average from a dataset of 100,000 wells. Perhaps enough wells are above this threshold value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profit Calculation Execution\n",
    "\n",
    "A function wil be created to determine which region will produce the greatest profit. The function will first locate the top predicted volume values from each region. Volume reserves of actual values that match with the predicted best wells will be added together to form the revenue. The budget will then be deducted from the revenue produced to leave the profit from the region. The region with the most profit will be discovered. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Profit Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to find wells with highest profit\n",
    "def profit(target, predictions):\n",
    "    # Find well locations with highest predcited volumes \n",
    "    predictions = predictions.sort_values(ascending=False).head(200).index\n",
    "    \n",
    "    # Find total reserves of wells with highest volume\n",
    "    total_volume = target.loc[predictions].sum()\n",
    "    \n",
    "    # Find revenue of wells with highest volume\n",
    "    revenue = total_volume * revenue_per_unit\n",
    "    \n",
    "    # Find profit of wells with highest volume\n",
    "    profit = round(revenue - budget, 2)\n",
    "    \n",
    "    return profit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application of Profit Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Region 1 profit: 33208260.43 \n",
      "\n",
      "Region 2 profit: 24150866.97 \n",
      "\n",
      "Region 3 profit: 27103499.64\n"
     ]
    }
   ],
   "source": [
    "# Find profit of wells in each region\n",
    "profit_1 = profit(target_valid_1, predictions_valid_1)\n",
    "print('Region 1 profit:', profit_1,'\\n')\n",
    "\n",
    "profit_2 = profit(target_valid_2, predictions_valid_2)\n",
    "print('Region 2 profit:', profit_2,'\\n')\n",
    "\n",
    "profit_3 = profit(target_valid_3, predictions_valid_3)\n",
    "print('Region 3 profit:', profit_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Findings\n",
    "\n",
    "After performing the profit function on all three regions, the first region produced the most. This profit comes in at `$33,208,260`, over `$6 million` more than the next region as a maximum potential profit value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regional Risk and Profit\n",
    "\n",
    "Profit and risk will be assessed using the bootstrapping method for each region. This requires randomly sampling 500 data points and calculating the profit when selecting the top 200 predicted volume reserves. This is repeated 1000 times. \n",
    "\n",
    "Risk is recorded by counting the number of samples that lead to negative profit. Regions that have a loss percentage higher than 2.5% percent will be disregarded when making a recommendation. Those that remain will compete based on highest profit. The confidence interval will be calculated to capture 95% of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to find profit using bootstrap technique\n",
    "def distr_profit(target, predictions):\n",
    "    \n",
    "    # Initialize loss counter\n",
    "    loss = 0\n",
    "    \n",
    "    # Save values as an empty list\n",
    "    values = []\n",
    "    \n",
    "    # Choose random state\n",
    "    state = RandomState(12345)\n",
    "    \n",
    "    for i in range(1000):\n",
    "        subsample_target = target.sample(n=500, replace=True, random_state=state)\n",
    "        subsample_predict = predictions[subsample_target.index]\n",
    "\n",
    "        subsample_profit = profit(subsample_target, subsample_predict)\n",
    "        \n",
    "        values.append(subsample_profit)\n",
    "        # Calculate loss\n",
    "        if subsample_profit < 0:\n",
    "            loss += 1\n",
    "    \n",
    "    # Express loss as a percentage\n",
    "    loss_percentage = (loss / 1000) * 100\n",
    "    \n",
    "    # Save values as a series\n",
    "    values = pd.Series(values)\n",
    "    \n",
    "    # Find average profit\n",
    "    mean = round(values.mean(),2)\n",
    "\n",
    "    # Lower confidence interval bound (0.025)\n",
    "    lower, upper = round(values.quantile(0.025),2), round(values.quantile(0.975),2)\n",
    "\n",
    "    return mean, (lower, upper), loss_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Region 1 bootstrapping values: \n",
      " Mean: 6007352.44 \n",
      " 95% Confidence Interval: (129483.32, 12311636.06) \n",
      " Loss Probability: 2.0 % \n",
      "\n",
      "Region 2 bootstrapping values: \n",
      " Mean: 6652410.58 \n",
      " 95% Confidence Interval: (1579884.81, 11976415.88) \n",
      " Loss Probability: 0.3 % \n",
      "\n",
      "Region 3 bootstrapping values: \n",
      " Mean: 6155597.23 \n",
      " 95% Confidence Interval: (-122184.95, 12306444.74) \n",
      " Loss Probability: 3.0 % \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate profit for each region with bootstrapping method\n",
    "mean_1, ci_95_1, loss_1 = distr_profit(target_valid_1, predictions_valid_1)\n",
    "print('Region 1 bootstrapping values:', '\\n', 'Mean:', mean_1, '\\n',  \n",
    "      '95% Confidence Interval:', (ci_95_1),\n",
    "      '\\n', 'Loss Probability:', loss_1, \"%\", '\\n')\n",
    "\n",
    "mean_2, ci_95_2, loss_2 = distr_profit(target_valid_2, predictions_valid_2)\n",
    "print('Region 2 bootstrapping values:', '\\n', 'Mean:', mean_2, '\\n',  \n",
    "      '95% Confidence Interval:', (ci_95_2),\n",
    "      '\\n', 'Loss Probability:', loss_2, \"%\", '\\n')\n",
    "\n",
    "\n",
    "mean_3, ci_95_3, loss_3 = distr_profit(target_valid_3, predictions_valid_3)\n",
    "print('Region 3 bootstrapping values:', '\\n', 'Mean:', mean_3, '\\n',  \n",
    "      '95% Confidence Interval:', (ci_95_3),\n",
    "      '\\n', 'Loss Probability:', loss_3, \"%\", '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Findings\n",
    "\n",
    "#### Risk\n",
    "\n",
    "Region 3 is disqualified due to having a loss percentage higher than 2.5%. Region 1 and 2 both fall below, with Region 2 only having a loss probability of 0.3%.\n",
    "\n",
    "#### Profit\n",
    "\n",
    "Bootstrapping suggests that Region 2 is the better choice, leading to a mean profit of `$6,652,410` whilst Region 1 averages half a million less.\n",
    "\n",
    "#### Recommendation\n",
    "\n",
    "Region 2 is the recommended region based on risk and profit for the above reasons. Whilst region 1 and 3 showed promise earlier in the analysis, the bootstrapping technique provided for a much higher profit than through others which only garnered results of half as much."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "### Data Preparation\n",
    "\n",
    "Packages were imported and data from three regions were brought in. The data was checked for data types, missing values and duplicate values. Some duplicate values were found by determined to be present due to chance.\n",
    "\n",
    "### Model Training\n",
    "\n",
    "The data was split and trained to create a model. The model predicted that Region 2 and 3 would have higher volumes of oil than Region 1.\n",
    "\n",
    "### Profit Calculation Preparation\n",
    "\n",
    "Data about costs and revenue were introduced. The breakeven point was determined to be 111,111 barrels of oil. This was much higher than the initial averages for all three regions.\n",
    "\n",
    "### Profit Calculcation Execution\n",
    "\n",
    "A profit function was created that found the actual volume of wells from the predicted model. Region 1 showed the most promise with a profit of around `$33 million`\n",
    "\n",
    "### Regional Risk and Profit\n",
    "\n",
    "Bootstrapping produced results that suggested the risk of Region 3 was too high. Region 2 was chosen as the recommended region due to higher profit at `$6.7 million`\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
